{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hugging Face Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForTokenClassification, \n",
    "    Trainer, \n",
    "    TrainingArguments,\n",
    "    DataCollatorForTokenClassification,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from datasets import Dataset as HFDataset\n",
    "from datasets import DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from seqeval.metrics import f1_score, precision_score, recall_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Constant Definition \n",
    "\n",
    "In this cell, IÂ´ll document the type of entities and their correspondant colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types of defined entities:\n",
      "  - ACTION: Direct commands or actions mentioned in the message\n",
      "  - SITUATION: Racing context or circumstance descriptions\n",
      "  - INCIDENT: Accidents or on-track events\n",
      "  - STRATEGY_INSTRUCTION: Strategic directives\n",
      "  - POSITION_CHANGE: References to overtakes or positions\n",
      "  - PIT_CALL: Specific calls for pit stops\n",
      "  - TRACK_CONDITION: Mentions of the track's state\n",
      "  - TECHNICAL_ISSUE: Mechanical or car-related problems\n",
      "  - WEATHER: References to weather conditions\n"
     ]
    }
   ],
   "source": [
    "# Define entity types and their descriptions\n",
    "ENTITY_TYPES = {\n",
    "    \"ACTION\": \"Direct commands or actions mentioned in the message\",\n",
    "    \"SITUATION\": \"Racing context or circumstance descriptions\",\n",
    "    \"INCIDENT\": \"Accidents or on-track events\",\n",
    "    \"STRATEGY_INSTRUCTION\": \"Strategic directives\",\n",
    "    \"POSITION_CHANGE\": \"References to overtakes or positions\",\n",
    "    \"PIT_CALL\": \"Specific calls for pit stops\",\n",
    "    \"TRACK_CONDITION\": \"Mentions of the track's state\",\n",
    "    \"TECHNICAL_ISSUE\": \"Mechanical or car-related problems\",\n",
    "    \"WEATHER\": \"References to weather conditions\"\n",
    "}\n",
    "\n",
    "# Color scheme for entity visualization\n",
    "ENTITY_COLORS = {\n",
    "    \"ACTION\": \"#4e79a7\",           # Blue\n",
    "    \"SITUATION\": \"#f28e2c\",         # Orange\n",
    "    \"INCIDENT\": \"#e15759\",          # Red\n",
    "    \"STRATEGY_INSTRUCTION\": \"#76b7b2\", # Teal\n",
    "    \"POSITION_CHANGE\": \"#59a14f\",   # Green\n",
    "    \"PIT_CALL\": \"#edc949\",          # Yellow\n",
    "    \"TRACK_CONDITION\": \"#af7aa1\",   # Purple\n",
    "    \"TECHNICAL_ISSUE\": \"#ff9da7\",   # Pink\n",
    "    \"WEATHER\": \"#9c755f\"            # Brown\n",
    "}\n",
    "\n",
    "print(\"Entity types defined:\")\n",
    "for entity, description in ENTITY_TYPES.items():\n",
    "    print(f\"  - {entity}: {description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load F1 radio data from JSON file\n",
    "def load_f1_radio_data(json_file):\n",
    "    \"\"\"Load and explore F1 radio data from JSON file\"\"\"\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    print(f\"Loaded {len(data)} messages from {json_file}\")\n",
    "    \n",
    "    # Show sample structure\n",
    "    if len(data) > 0:\n",
    "        print(\"\\nSample record structure:\")\n",
    "        sample = data[0]\n",
    "        print(f\"  Driver: {sample.get('driver', 'N/A')}\")\n",
    "        print(f\"  Radio message: {sample.get('radio_message', 'N/A')[:100]}...\")\n",
    "        \n",
    "        if 'annotations' in sample and len(sample['annotations']) > 1:\n",
    "            if isinstance(sample['annotations'][1], dict) and 'entities' in sample['annotations'][1]:\n",
    "                entities = sample['annotations'][1]['entities']\n",
    "                print(f\"  Number of entities: {len(entities)}\")\n",
    "                if len(entities) > 0:\n",
    "                    entity = entities[0]\n",
    "                    entity_text = sample['radio_message'][entity[0]:entity[1]]\n",
    "                    print(f\"  Sample entity: [{entity[0]}, {entity[1]}, '{entity_text}', '{entity[2]}']\")\n",
    "    \n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 529 messages from f1_radio_entity_annotations.json\n",
      "\n",
      "Sample record structure:\n",
      "  Driver: 1\n",
      "  Radio message: So don't forget Max, use your head please. Are we both doing it or what? You just follow my instruct...\n",
      "  Number of entities: 3\n",
      "  Sample entity: [82, 103, 'follow my instruction', 'ACTION']\n",
      "\n",
      "Entity type distribution in dataset:\n",
      "  - SITUATION: 255\n",
      "  - ACTION: 165\n",
      "  - STRATEGY_INSTRUCTION: 137\n",
      "  - TECHNICAL_ISSUE: 137\n",
      "  - WEATHER: 112\n",
      "  - POSITION_CHANGE: 83\n",
      "  - INCIDENT: 78\n",
      "  - TRACK_CONDITION: 62\n",
      "  - PIT_CALL: 42\n"
     ]
    }
   ],
   "source": [
    "# Load the JSON data\n",
    "json_file_path = \"f1_radio_entity_annotations.json\"\n",
    "f1_data = load_f1_radio_data(json_file_path)\n",
    "\n",
    "# Count entity types in the dataset\n",
    "entity_counts = {}\n",
    "for item in f1_data:\n",
    "    if 'annotations' in item and len(item['annotations']) > 1:\n",
    "        if isinstance(item['annotations'][1], dict) and 'entities' in item['annotations'][1]:\n",
    "            for _, _, entity_type in item['annotations'][1]['entities']:\n",
    "                entity_counts[entity_type] = entity_counts.get(entity_type, 0) + 1\n",
    "\n",
    "print(\"\\nEntity type distribution in dataset:\")\n",
    "for entity_type, count in sorted(entity_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"  - {entity_type}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Preprocessing F1 Radio Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_f1_data(data):\n",
    "    \"\"\"Extract and preprocess F1 radio data with valid annotations\"\"\"\n",
    "    processed_data = []\n",
    "    skipped_count = 0\n",
    "    \n",
    "    for item in data:\n",
    "        if 'radio_message' not in item or 'annotations' not in item:\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "            \n",
    "        text = item['radio_message']\n",
    "        \n",
    "        # Skip items with empty or null text\n",
    "        if not text or text.strip() == \"\":\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "            \n",
    "        # Extract entities if they exist in expected format\n",
    "        if len(item['annotations']) > 1 and isinstance(item['annotations'][1], dict):\n",
    "            annotations = item['annotations'][1]\n",
    "            if 'entities' in annotations and annotations['entities']:\n",
    "                entities = annotations['entities']\n",
    "                \n",
    "                # Add to processed data\n",
    "                processed_data.append({\n",
    "                    'text': text,\n",
    "                    'entities': entities,\n",
    "                    'driver': item.get('driver', None)\n",
    "                })\n",
    "            else:\n",
    "                skipped_count += 1\n",
    "        else:\n",
    "            skipped_count += 1\n",
    "    \n",
    "    print(f\"Processed {len(processed_data)} messages with valid annotations\")\n",
    "    print(f\"Skipped {skipped_count} messages with missing or invalid annotations\")\n",
    "    \n",
    "    # Show a sample of processed data\n",
    "    if processed_data:\n",
    "        sample = processed_data[10]\n",
    "        print(\"\\nSample processed message:\")\n",
    "        print(f\"Text: {sample['text']}\")\n",
    "        print(\"Entities:\")\n",
    "        for start, end, entity_type in sample['entities']:\n",
    "            entity_text = sample['text'][start:end]\n",
    "            print(f\"  - [{start}, {end}] '{entity_text}' ({entity_type})\")\n",
    "    \n",
    "    return processed_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 399 messages with valid annotations\n",
      "Skipped 130 messages with missing or invalid annotations\n",
      "\n",
      "Sample processed message:\n",
      "Text: I have to join the Slums because my tyres are f***ed. Understood Max. It might just be survival in that section of track, Max, if the rest of the track is dry.\n",
      "Entities:\n",
      "  - [87, 120] 'survival in that section of track' (ACTION)\n",
      "  - [0, 24] 'I have to join the Slums' (STRATEGY_INSTRUCTION)\n",
      "  - [127, 158] 'if the rest of the track is dry' (TRACK_CONDITION)\n",
      "  - [127, 158] 'if the rest of the track is dry' (WEATHER)\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the loaded data\n",
    "processed_f1_data = preprocess_f1_data(f1_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "f1_strat_manager",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
