{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate a real classifier\n",
    "\n",
    "This code is an example of the use of VADER classifier from NLTK. It is a Naive-Bayes classifier that is trainded with a lexicon and dataset of movie reviews.\n",
    "\n",
    "Look in the example how the library SKLearn is used to evaulate the classifier.\n",
    "\n",
    "At the end you have an example on how to use the classifier en custom examples. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.classify.util import accuracy\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\victo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\victo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\victo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\victo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download required NLTK datasets\n",
    "nltk.download('movie_reviews')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def extract_features(words):\n",
    "    return {word: True for word in words if word.lower() not in stop_words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the dataset\n",
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "             for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)]\n",
    "random.shuffle(documents)  # Shuffle the dataset for better randomness\n",
    "\n",
    "# Feature extraction\n",
    "feature_sets = [(extract_features(words), category) for (words, category) in documents]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_size = int(len(feature_sets) * 0.8)\n",
    "train_set, test_set = feature_sets[:train_size], feature_sets[train_size:]\n",
    "\n",
    "# Train a Naive Bayes Classifier\n",
    "classifier = NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Naive Bayes Classifier Evaluation:\n",
      "Accuracy: 70.75%\n",
      "Most Informative Features\n",
      "             outstanding = True              pos : neg    =     15.4 : 1.0\n",
      "                  avoids = True              pos : neg    =     12.5 : 1.0\n",
      "               ludicrous = True              neg : pos    =     12.1 : 1.0\n",
      "              brilliance = True              pos : neg    =     11.1 : 1.0\n",
      "              astounding = True              pos : neg    =     10.4 : 1.0\n",
      "                captures = True              pos : neg    =     10.3 : 1.0\n",
      "               addresses = True              pos : neg    =      9.8 : 1.0\n",
      "            lighthearted = True              pos : neg    =      9.8 : 1.0\n",
      "                    slip = True              pos : neg    =      9.8 : 1.0\n",
      "                  stinks = True              neg : pos    =      9.6 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the classifier\n",
    "print(\"\\nNaive Bayes Classifier Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy(classifier, test_set) * 100:.2f}%\")\n",
    "classifier.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       1.00      0.40      0.57       196\n",
      "         pos       0.64      1.00      0.78       204\n",
      "\n",
      "    accuracy                           0.71       400\n",
      "   macro avg       0.82      0.70      0.68       400\n",
      "weighted avg       0.81      0.71      0.68       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare predictions and true labels for sklearn metrics\n",
    "y_true = [label for (_, label) in test_set]\n",
    "y_pred = [classifier.classify(features) for (features, _) in test_set]\n",
    "# Evaluate using sklearn metrics\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 79 117]\n",
      " [  0 204]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "# VADER Sentiment Analysis on custom examples\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "example_sentences = [\n",
    "    \"I absolutely loved this movie! The acting was fantastic.\",\n",
    "    \"This was the worst film I have ever seen.\",\n",
    "    \"The plot was predictable, but the cinematography was beautiful.\",\n",
    "    \"I wouldn't recommend it. It was boring and too long.\"\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VADER Sentiment Analysis:\n",
      "Sentence: I absolutely loved this movie! The acting was fantastic.\n",
      "Sentiment: positive (Score: 0.8436)\n",
      "\n",
      "Sentence: This was the worst film I have ever seen.\n",
      "Sentiment: negative (Score: -0.6249)\n",
      "\n",
      "Sentence: The plot was predictable, but the cinematography was beautiful.\n",
      "Sentiment: positive (Score: 0.7469)\n",
      "\n",
      "Sentence: I wouldn't recommend it. It was boring and too long.\n",
      "Sentiment: negative (Score: -0.5283)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nVADER Sentiment Analysis:\")\n",
    "for sentence in example_sentences:\n",
    "    score = sia.polarity_scores(sentence)\n",
    "    sentiment = \"positive\" if score['compound'] > 0 else \"negative\"\n",
    "    print(f\"Sentence: {sentence}\\nSentiment: {sentiment} (Score: {score['compound']})\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise:\n",
    "\n",
    "Create your own gold standard and measure Precission, Recall, and F1 manually and with SKLearn to check if the result is the same. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Creating the gold standard\n",
    "\n",
    "IÂ´ll create a list of tuples with 14 examples of phrases with positive and negative meanings, using the variable `gold_standard`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our gold standard data - manually labeled examples\n",
    "gold_standard = [\n",
    "    (\"The movie was absolutely fantastic, I loved every minute of it\", \"pos\"),\n",
    "    (\"The actors delivered terrible performances, complete waste of time\", \"neg\"),\n",
    "    (\"While the special effects where great, the story was boring\", \"neg\"),\n",
    "    (\"I found the plot somewhat predictable but still enjoyed it\", \"pos\"),\n",
    "    (\"The plot was interesting, but the performance of the actors made it hard to watch\", \"neg\"),\n",
    "    (\"One of the best movies I have seen this year\", \"pos\"),\n",
    "    (\"Terrible movie, I would love if I could ask for a refund after watching it\", \"neg\"),\n",
    "    (\"The director's vision really shines through in every scene\", \"pos\"),\n",
    "    (\"Despite the large budget, the film feels cheap and rushed\", \"neg\"),\n",
    "    (\"I was moved to tears by the powerful performances\", \"pos\"),\n",
    "    (\"The dialogue was so poorly written it became unintentionally funny\", \"neg\"),\n",
    "    (\"A masterpiece that will be remembered for generations\", \"pos\"),\n",
    "    (\"The cinematography was stunning even though the plot had some holes\", \"pos\"),\n",
    "    (\"Too long and drawn out, I found myself checking my watch repeatedly\", \"neg\"),\n",
    "    (\"An average film that neither impresses nor disappoints\", \"neg\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Separating the gold Standard Data into texts and labels\n",
    "\n",
    "I do not extract the stopwords as Vader knows them, so I can skip this step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the first element of the tuples for the texts\n",
    "texts = [value[0] for value in gold_standard]\n",
    "\n",
    "# Extract the second element of the tuples for pos neg labels\n",
    "true_labels = [value[1] for value in gold_standard]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The movie was absolutely fantastic, I loved every minute of it', 'The actors delivered terrible performances, complete waste of time', 'While the special effects where great, the story was boring', 'I found the plot somewhat predictable but still enjoyed it', 'The plot was interesting, but the performance of the actors made it hard to watch', 'One of the best movies I have seen this year', 'Terrible movie, I would love if I could ask for a refund after watching it', \"The director's vision really shines through in every scene\", 'Despite the large budget, the film feels cheap and rushed', 'I was moved to tears by the powerful performances', 'The dialogue was so poorly written it became unintentionally funny', 'A masterpiece that will be remembered for generations', 'The cinematography was stunning even though the plot had some holes', 'Too long and drawn out, I found myself checking my watch repeatedly', 'An average film that neither impresses nor disappoints']\n",
      "['pos', 'neg', 'neg', 'pos', 'neg', 'pos', 'neg', 'pos', 'neg', 'pos', 'neg', 'pos', 'pos', 'neg', 'neg']\n"
     ]
    }
   ],
   "source": [
    "print(texts)\n",
    "\n",
    "print(true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nVADER Sentiment Analysis in custom gold Standard:\")\n",
    "for sentence in texts:\n",
    "    score = sia.polarity_scores(sentence)\n",
    "    sentiment = \"positive\" if score['compound'] > 0 else \"negative\"\n",
    "    print(f\"Sentence: {sentence}\\nSentiment: {sentiment} (Score: {score['compound']})\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aprendizaje_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
