{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvNCXd9Dfqe1"
      },
      "source": [
        "# Word2vec with gensim\n",
        "\n",
        "In this Jupyter notebook you will use the [Gensim] library (https://radimrehurek.com/gensim/index.html) to experiment with Word2VEC.This notebook is focused on the intuition of the concepts and not on the implementation details.This notebook is inspired by this [Guide] (https://radicrehurek.com/gensim/auto_examples/ttorials/run_word2vec.html).\n",
        "\n",
        "## 1. Installation and loading the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "zKIqnDXXfpiz"
      },
      "outputs": [],
      "source": [
        "#!pip install --upgrade gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "Sn7Q2jB3frOn"
      },
      "outputs": [],
      "source": [
        "import gensim.downloader as api"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "yBaT8djWkaZy"
      },
      "outputs": [],
      "source": [
        "model = api.load('word2vec-google-news-300')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVZm7iTOoawW"
      },
      "source": [
        "## 2. Similarity of words\n",
        "\n",
        "In this section we will see how to achieve the similarity between two words using a Word Embedding already trained."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "kOZfaelLoi4c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.6510957"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.similarity(\"king\", \"queen\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "BX-Kk9HZofuF"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.22942671"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.similarity(\"king\", \"man\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "ypFK-pLrol3N"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.09978464"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.similarity(\"king\", \"potato\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "rBWzZySFormq"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.similarity(\"king\", \"king\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GijWs_tx83W"
      },
      "source": [
        "Now we will see how to find the words with greater similarity to the set of specified words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "ytELAWBLk2-6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('monarch', 0.7042065858840942),\n",
              " ('kings', 0.6780862808227539),\n",
              " ('princess', 0.6731551885604858),\n",
              " ('queens', 0.6679496765136719),\n",
              " ('prince', 0.6435247659683228)]"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.most_similar([\"king\", \"queen\"], topn=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "7D4ZS7N3ovxB"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('carrots', 0.7536594867706299),\n",
              " ('tomatoes', 0.712963879108429),\n",
              " ('celery', 0.7025030851364136),\n",
              " ('broccoli', 0.6796349883079529),\n",
              " ('cherry_tomatoes', 0.662927508354187)]"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.most_similar([\"tomato\", \"carrot\"], topn=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZFlxKjOyBpu"
      },
      "source": [
        "But you can even do interesting things such as seeing what word does not correspond to a list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "8CrZdcBpn3pn"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'air'"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.doesnt_match([\"summer\", \"fall\", \"spring\", \"air\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ko09hZ3dqMZ1"
      },
      "source": [
        "## Exercises\n",
        "\n",
        "1. Use the Word2VEC model to make a ranking of the following 15 words according to its similarity with the words \"man\" and \"Woman\".For each pair, it prints its similarity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "vzZ1eD3PpT-d"
      },
      "outputs": [],
      "source": [
        "words = [\n",
        "\"wife\",\n",
        "\"husband\",\n",
        "\"child\",\n",
        "\"queen\",\n",
        "\"king\",\n",
        "\"man\",\n",
        "\"woman\",\n",
        "\"birth\",\n",
        "\"doctor\",\n",
        "\"nurse\",\n",
        "\"teacher\",\n",
        "\"professor\",\n",
        "\"engineer\",\n",
        "\"scientist\",\n",
        "\"president\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Axuliar functions that I do not use anymore but that I want to keep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Making pairs from the words list\n",
        "# def make_pairs(words):\n",
        "#     word_pairs = []\n",
        "#     for first_word in range(len(words)):\n",
        "#         for second_word in range(first_word + 1, len(words)):\n",
        "#             word_pairs.append((words[first_word], words[second_word]))\n",
        "#     return word_pairs\n",
        "\n",
        "# print(make_pairs(words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Now I can calculate word similiratity \n",
        "\n",
        "# word_pairs = make_pairs(words)\n",
        "# def calculate_similarity(word_pairs):\n",
        "#     for word_1, word_2 in word_pairs:\n",
        "#         similarity = model.similarity(word_1, word_2)\n",
        "#         print(f\"Similarity between {word_1} and {word_2}: {similarity}\")\n",
        "\n",
        "#     return similarity\n",
        "\n",
        "# print(calculate_similarity(word_pairs))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'Man' similarity ranking:\n",
            "Word: man, Similarity with 'man': 1.0\n",
            "Word: woman, Similarity with 'man': 0.7664012312889099\n",
            "Word: husband, Similarity with 'man': 0.34499746561050415\n",
            "Word: wife, Similarity with 'man': 0.3292091488838196\n",
            "Word: child, Similarity with 'man': 0.3163333833217621\n",
            "Word: doctor, Similarity with 'man': 0.31448960304260254\n",
            "Word: nurse, Similarity with 'man': 0.25472286343574524\n",
            "Word: teacher, Similarity with 'man': 0.25000131130218506\n",
            "Word: king, Similarity with 'man': 0.22942671179771423\n",
            "Word: queen, Similarity with 'man': 0.16658204793930054\n",
            "Word: scientist, Similarity with 'man': 0.1582496464252472\n",
            "Word: engineer, Similarity with 'man': 0.15128928422927856\n",
            "Word: birth, Similarity with 'man': 0.11078789830207825\n",
            "Word: professor, Similarity with 'man': 0.09415861964225769\n",
            "Word: president, Similarity with 'man': 0.028424618765711784\n",
            "\n",
            "'Woman' similarity ranking:\n",
            "Word: woman, Similarity with 'woman': 1.0\n",
            "Word: man, Similarity with 'woman': 0.7664012312889099\n",
            "Word: husband, Similarity with 'woman': 0.4928138256072998\n",
            "Word: child, Similarity with 'woman': 0.475003719329834\n",
            "Word: wife, Similarity with 'woman': 0.4448239803314209\n",
            "Word: nurse, Similarity with 'woman': 0.44135597348213196\n",
            "Word: doctor, Similarity with 'woman': 0.37945860624313354\n",
            "Word: queen, Similarity with 'woman': 0.31618136167526245\n",
            "Word: teacher, Similarity with 'woman': 0.31357842683792114\n",
            "Word: birth, Similarity with 'woman': 0.2147129476070404\n",
            "Word: scientist, Similarity with 'woman': 0.1548689752817154\n",
            "Word: professor, Similarity with 'woman': 0.13077852129936218\n",
            "Word: king, Similarity with 'woman': 0.1284797340631485\n",
            "Word: engineer, Similarity with 'woman': 0.09435376524925232\n",
            "Word: president, Similarity with 'woman': 0.06267671287059784\n"
          ]
        }
      ],
      "source": [
        "similarities_man = []\n",
        "similarities_woman = []\n",
        "\n",
        "for word in words:\n",
        "    sim_man = model.similarity(\"man\", word)\n",
        "    sim_woman = model.similarity(\"woman\", word)\n",
        "\n",
        "\n",
        "    similarities_man.append((word, sim_man))\n",
        "    similarities_woman.append((word, sim_woman))\n",
        "\n",
        "# Sorting similarities in descendant order\n",
        "\n",
        "# lamda says that the list must be ordered by the second element of the tuple, that is, the similarity value\n",
        "similarities_man = sorted(similarities_man, key=lambda x: x[1], reverse=True)\n",
        "similarities_woman = sorted(similarities_woman, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "\n",
        "\n",
        "# Print ranking\n",
        "print(\"'Man' similarity ranking:\")\n",
        "for word, similarity in similarities_man:\n",
        "    print(f\"Word: {word}, Similarity with 'man': {similarity}\")\n",
        "\n",
        "print(\"\\n'Woman' similarity ranking:\")\n",
        "for word, similarity in similarities_woman:\n",
        "    print(f\"Word: {word}, Similarity with 'woman': {similarity}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKamywnxqxJJ"
      },
      "source": [
        "** 2. Complete the following analogies on your own (without using the model) **\n",
        "\n",
        "a. king is to throne as judge is to `courts`\n",
        "\n",
        "b. giant is to dwarf as genius is to `silly`\n",
        "\n",
        "c. French is to France as Spaniard is to `Spain`\n",
        "\n",
        "d. bad is to good as sad is to `happy`\n",
        "\n",
        "e. nurse is to hospital as teacher is to `school`\n",
        "\n",
        "f. universe is to planet as house is to `neighborhood`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('appellate_court', 0.584525465965271)]"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# a. king is to throne as judge is to `courts`\n",
        "model.most_similar(positive=[\"throne\", \"judge\"], negative=[\"king\"], topn=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('savant', 0.44152510166168213)]"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# b. giant is to dwarf as genius is to `silly`\n",
        "model.most_similar(positive=[\"dwarf\", \"genius\"], negative=[\"giant\"], topn=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('rider_Dani_Pedrosa', 0.5646752715110779)]"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# c. French is to France as Spaniard is to `Spain`\n",
        "\n",
        "model.most_similar(positive=[\"France\", \"Spaniard\"], negative=[\"French\"], topn=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('sad', 0.5258649587631226)]"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# d. bad is to good as sad is to `happy`\n",
        "model.most_similar(positive=[\"Bad\", \"Sad\"], negative=[\"Good\"], topn=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('school', 0.60170978307724)]"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# e. nurse is to hospital as teacher is to `school`\n",
        "model.most_similar(positive=[\"hospital\", \"teacher\"], negative=[\"nurse\"], topn=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('bungalow', 0.5428239703178406)]"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# f. universe is to planet as house is to `neighborhood`\n",
        "model.most_similar(positive=[\"planet\", \"house\"], negative=[\"universe\"], topn=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcNRxHuZrXAM"
      },
      "source": [
        "**3. Ahora completa las analogías usando un modelo word2vec**\n",
        "\n",
        "Aquí hay un ejemplo de cómo hacerlo. Puedes resolver analogías como \"A es a B como C es a _\" haciendo A + C - B. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "K4kF08h4qhxM"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('queen', 0.7118193507194519)]"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# man is to woman as king is to ___?\n",
        "model.most_similar(positive=[\"king\", \"woman\"], negative=[\"man\"], topn=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "DiPbbGsori48"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('taco', 0.6266060471534729)]"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# us is to burger as italy is to ___?\n",
        "model.most_similar(positive=[\"Mexico\", \"burger\"], negative=[\"USA\"], topn=1)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOnghp0wIfCZSJ+lSjdKnPj",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "Word2vec.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tensorflow_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
