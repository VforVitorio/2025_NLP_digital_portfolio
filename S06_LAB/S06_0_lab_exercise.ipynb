{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S06 Lab Exercise \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Víctor Vega Sobral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\victo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Sentence Segmentation-------\n",
      "['The president of the U.S.A., Donald Trump, is 1.9m high and 78 years old.', 'Forbes Magazine has assessed his wealth, currently estimating it at $5.5 billion as of mid-February 2025.']\n"
     ]
    }
   ],
   "source": [
    "# For the next text, perform the following actions\n",
    "text = \"The president of the U.S.A., Donald Trump, is 1.9m high and 78 years old. Forbes Magazine has assessed his wealth, currently estimating it at $5.5 billion as of mid-February 2025.\"\n",
    "\n",
    "# (1 point) 1 - Use NLTK to split the sentences \n",
    "\n",
    "print(\"-------Sentence Segmentation-------\")\n",
    "sentence_tokenization = nltk.sent_tokenize(text, language='english')\n",
    "print(sentence_tokenization)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The president of the USA, Donald Trump, is 190 centimeters high and 78 years old.\n",
      "Forbes Magazine has assessed his wealth, currently estimating it at 5 point 5 billion as of mid-February 2025.\n",
      "['The president of the USA, Donald Trump, is 190 centimeters high and 78 years old.', 'Forbes Magazine has assessed his wealth, currently estimating it at 5 point 5 billion as of mid-February 2025.']\n"
     ]
    }
   ],
   "source": [
    "# (2 points) 2 - Convert with regex the acronym U.S.A. to USA, \n",
    "# the number 1.9m to 190 centimeters or any other number of a height like that \n",
    "# (e.g. 1.75m to 175 centimeters), and \"$5.5 billion\" to five point five billion. \n",
    "\n",
    "\n",
    "# ACRONIM\n",
    "# b delimits start and end of word\n",
    "# b capture with parenthesis sequence of upper case with a point, at least one that can be more\n",
    "\n",
    "def remove_dots(regex_match):\n",
    "    # regex_match.group(0) retuns the complete subchain that matches the regex pattern.\n",
    "    # with replace eliminates the points\n",
    "    return regex_match.group(0).replace(\".\", \"\")\n",
    "\n",
    "def convert_meters_to_cm(regex_match):\n",
    "    # we need 1 to not capture the m\n",
    "    meters = float(regex_match.group(1))  # Obtains number in meters using the regex and turns it from str to float\n",
    "    # group 1 for only first capture \n",
    "    centimeters = int(meters * 100)  # Converts to cm without decimals, cm are always integers\n",
    "    return f\"{centimeters} centimeters\"\n",
    "\n",
    "def convert_numbers_to_text(regex_match):\n",
    "    # use 1 for not capturing the dollar and \"billion\"\n",
    "    number = regex_match.group(1)  # Extracts captured number, only the first capture \n",
    "    return f\"{number} billion\".replace(\".\", \" point \")  # Decimals for point\n",
    "\n",
    "\n",
    "# we add a lookahead for  assuring a non alphanumeric or end of the sequence\n",
    "acronim_reg = r\"\\b(?:[A-Z]\\.)+(?=\\W|$)\"\n",
    "\n",
    "\n",
    "meters_to_cm_reg = r\"\\b(\\d+\\.\\d+)m\\b\"\n",
    "# \n",
    "# \\b for lomiting the word.\n",
    "# (\\d+\\.\\d+) captures number with decimals. \n",
    "# m for letter of metes\n",
    "# \\b assures end of word\n",
    "\n",
    "numbers_to_letters = r\"\\$(\\d+\\.\\d+) billion\"\n",
    "\n",
    "#escapes the dollar symbol for not being put as end of word\n",
    "# (\\d+\\.\\d+) captures again the decimals like in the previous regex\n",
    "# assures being in   billion\n",
    "\n",
    "text_cleaned = []\n",
    "for sentence in sentence_tokenization:\n",
    "    sentence = re.sub(acronim_reg, remove_dots, sentence)\n",
    "    sentence = re.sub(meters_to_cm_reg, convert_meters_to_cm, sentence)\n",
    "    sentence = re.sub(numbers_to_letters, convert_numbers_to_text, sentence)\n",
    "    print(sentence)\n",
    "    text_cleaned.append(sentence)\n",
    "\n",
    "print(text_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The president of the USA,_Donald_Trump, is 190 centimeters high and 78 years old. Forbes_Magazine has assessed his wealth, currently estimating it at 5 point 5 billion as of mid-february 2025.\n"
     ]
    }
   ],
   "source": [
    "# (1 point) 3 - Convert to lowercase except the proper nouns that must keep the original case. \n",
    "# For the multiword proper names convert them \n",
    "# o an unique word joining the two word with underscoere (Juan Fernández -> Juan_Fernández).\n",
    "text_cleaned_string = \" \".join(text_cleaned)\n",
    "text_lowered = text_cleaned_string.lower()\n",
    "\n",
    "words = text_cleaned_string.split()\n",
    "# List for processing the words\n",
    "results = []\n",
    "\n",
    "for i in range(len(words)):\n",
    "    # words[i] finds the word and [0] the first char of the word\n",
    "    if words[i][0].isupper():  # If the word starts with uppercase is a proper name \n",
    "        # if the previous word is word [i-1], [0] again for first char\n",
    "        if i > 0 and words[i - 1][0].isupper():  \n",
    "            # If last word is also upper case, we add a _ to it \n",
    "            # we put concatene to the last word stroed in results these word\n",
    "            # for the example, when finds \"Trump\", adds to Donald in results a _Trump\n",
    "            results[-1] += \"_\" + words[i]\n",
    "        else:\n",
    "            results.append(words[i])  # Else, we maintain it\n",
    "    else:\n",
    "        results.append(words[i].lower())  # If is not a proper name, we convert the word to lower case\n",
    "\n",
    "text_lowered = \" \".join(results) # turn the list to a string again, but now for text lowered\n",
    "\n",
    "\n",
    "print(text_lowered)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Word Tokenization ---\n",
      "['The', 'president', 'of', 'the', 'USA', ',', '_Donald_Trump', ',', 'is', '190', 'centimeters', 'high', 'and', '78', 'years', 'old', '.', 'Forbes_Magazine', 'has', 'assessed', 'his', 'wealth', ',', 'currently', 'estimating', 'it', 'at', '5', 'point', '5', 'billion', 'as', 'of', 'mid-february', '2025', '.']\n"
     ]
    }
   ],
   "source": [
    "# (1 point) 4 - Tokenize the text (use the tool you prefer). \n",
    "print(\"\\n--- Word Tokenization ---\")\n",
    "\n",
    "word_tokenization = nltk.word_tokenize(text_lowered, language=\"spanish\")\n",
    "print(word_tokenization)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Sentence \n",
      "The president USA , _Donald_Trump , 190 centimeters high 78 years old . Forbes_Magazine assessed wealth , currently estimating 5 point 5 billion mid-february 2025 .\n"
     ]
    }
   ],
   "source": [
    "# (1 point) 5 - Remove the stopwords (use the tool you prefer). \n",
    "from nltk.corpus import stopwords\n",
    "#nltk.download(\"stopwords\") only made once for downloading\n",
    "\n",
    "# Define the stopwords in english\n",
    "stop_words = set(stopwords.words('english')) \n",
    "filtered_sentence = [] \n",
    "  \n",
    "for word in word_tokenization: \n",
    "    # If the word is not a stop word, we add it to the list of filtered sentence\n",
    "    if word not in stop_words: \n",
    "        filtered_sentence.append(word) \n",
    "\n",
    "print(\"Filtered Sentence \")\n",
    "# turn again to a string to see the text\n",
    "filtered_string = (\" \".join(filtered_sentence))\n",
    "print(filtered_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'president']\n",
      "['president', 'USA']\n",
      "['USA', ',']\n",
      "[',', '_Donald_Trump']\n",
      "['_Donald_Trump', ',']\n",
      "[',', '190']\n",
      "['190', 'centimeters']\n",
      "['centimeters', 'high']\n",
      "['high', '78']\n",
      "['78', 'years']\n",
      "['years', 'old']\n",
      "['old', '.']\n",
      "['.', 'Forbes_Magazine']\n",
      "['Forbes_Magazine', 'assessed']\n",
      "['assessed', 'wealth']\n",
      "['wealth', ',']\n",
      "[',', 'currently']\n",
      "['currently', 'estimating']\n",
      "['estimating', '5']\n",
      "['5', 'point']\n",
      "['point', '5']\n",
      "['5', 'billion']\n",
      "['billion', 'mid-february']\n",
      "['mid-february', '2025']\n",
      "['2025', '.']\n"
     ]
    }
   ],
   "source": [
    "# (1 point) 6 - Create bigrams with pure python.\n",
    "\n",
    "string_for_bigram = filtered_string.split()\n",
    "# print(string_for_bigram)\n",
    "\n",
    "N = 2\n",
    "# with slicing, we start from i to i + N as last index of the slice \n",
    "# then list from i to N\n",
    "# range(len(string_for_bigram) - N + 1 defines the maximum positions in the list,\n",
    "# for example 5 words with this no limitation would go for a slice of 4:6 that is out of the bigrams.\n",
    "# using list compression for better for loop\n",
    "\n",
    "#\n",
    "# the slice string_for_bigram[4:6] would try to access an index outside the list boundaries.\n",
    "bigrams = [string_for_bigram[i: i + N] for i in range(len(string_for_bigram) - N + 1)]\n",
    "\n",
    "\n",
    "for bigram in bigrams:\n",
    "    print(bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2 point) 7 - Create a language model that predict the next word using bigrams. Please explain in the code how you made the calculations.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aprendizaje_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
