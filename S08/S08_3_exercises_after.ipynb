{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM classificator\n",
    "\n",
    "Using the dataset `dataset_emails.csv` (or the same dataset you have used in S08_1) create a some text classificators:\n",
    "* LSTM\n",
    "* GRU \n",
    "\n",
    "Compare the results between LSTM and GRU. Compare the results with the S08_1 methods. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, GRU\n",
    "from tensorflow.keras.metrics import Precision, Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the Dataset\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "prompt",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "53f61cc5-6230-443f-bb3b-f9699f3d0f77",
       "rows": [
        [
         "0",
         "Can I send an email, please?",
         "send"
        ],
        [
         "1",
         "I'd like to compose an email.",
         "send"
        ],
        [
         "2",
         "I need to send an email.",
         "send"
        ],
        [
         "3",
         "Could you help me write an email?",
         "send"
        ],
        [
         "4",
         "Is it possible to send an email with you?",
         "send"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can I send an email, please?</td>\n",
       "      <td>send</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'd like to compose an email.</td>\n",
       "      <td>send</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I need to send an email.</td>\n",
       "      <td>send</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Could you help me write an email?</td>\n",
       "      <td>send</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Is it possible to send an email with you?</td>\n",
       "      <td>send</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      prompt label\n",
       "0               Can I send an email, please?  send\n",
       "1              I'd like to compose an email.  send\n",
       "2                   I need to send an email.  send\n",
       "3          Could you help me write an email?  send\n",
       "4  Is it possible to send an email with you?  send"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"dataset_emails.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   prompt  1000 non-null   object\n",
      " 1   label   1000 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 15.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dividing in train and test split\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples:  800\n",
      "Test samples:  200\n"
     ]
    }
   ],
   "source": [
    "X = df[\"prompt\"]\n",
    "y = df[\"label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state= 42)\n",
    "\n",
    "print(\"Train samples: \", len(X_train))\n",
    "print(\"Test samples: \", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tokenization and Padding\n",
    "\n",
    "We need to convert the test to a sequence of numbers, using the KerasÂ´tokenizer.\n",
    "\n",
    "* *num_words*: define the maximum number of words to take into account. Example: 10000 most frequent words.\n",
    "* *max_len*: maximum length of each sequence. If a sequence is shorter, it will be filled; if longer, will be clipped.\n",
    "\n",
    "This step is important for having data prepared for LSTM nets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization parameters\n",
    "\n",
    "max_words = 10000 # Maximum of words to take into consideration\n",
    "max_len = 100 # Maximum len sequence\n",
    "\n",
    "# Instanciate and adjust tokenizator over train set\n",
    "\n",
    "tokenizer = Tokenizer(num_words = max_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# Convert texts to numeric sequences\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Applying padding for obtaining fixed len sequences\n",
    "X_train_pad = pad_sequences(X_train_seq,maxlen = max_len)\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen = max_len)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. LSTM Construction\n",
    "\n",
    "A basic model architecture would be the following: \n",
    "\n",
    "1. **An embedding layer**: converts each word, represented as an integer, into a dense vector.\n",
    "2. **A LSTM layer**: process the sequences and captures dependencies over time.\n",
    "3. **A final dense layer**: for class prediction (for example, sigmoid activation for binary classification or softmax for multi-class classification)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 One-hot encoding\n",
    "\n",
    "I will turn labels into binary vectors using loss function `categorical_crossentropy`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes is 10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Codifying labels \n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "y_test_enc = le.fit_transform(y_test)\n",
    "\n",
    "# Converting to one-hot\n",
    "y_train_cat = to_categorical(y_train_enc)\n",
    "y_test_cat = to_categorical(y_test_enc)\n",
    "\n",
    "# Number of classes\n",
    "\n",
    "num_classes = len(le.classes_)\n",
    "\n",
    "print(f\"Number of classes is {num_classes}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 LSTM Architecture\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim = max_words, output_dim = 128, input_length = max_len)) # Embedding layer\n",
    "model.add(LSTM(64)) \n",
    "model.add(Dense(num_classes, activation = \"softmax\")) # Output layer ith softmax activation\n",
    "\n",
    "\n",
    "# Model compilation with categorical cross-entropy \n",
    "\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\", Precision(), Recall()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 LSTM Training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "23/23 [==============================] - 2s 34ms/step - loss: 2.2806 - accuracy: 0.3125 - precision_3: 0.0000e+00 - recall_3: 0.0000e+00 - val_loss: 2.2578 - val_accuracy: 0.2250 - val_precision_3: 0.0000e+00 - val_recall_3: 0.0000e+00\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 2.1413 - accuracy: 0.3556 - precision_3: 0.0000e+00 - recall_3: 0.0000e+00 - val_loss: 2.0613 - val_accuracy: 0.3250 - val_precision_3: 0.0000e+00 - val_recall_3: 0.0000e+00\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 1.7575 - accuracy: 0.4847 - precision_3: 1.0000 - recall_3: 0.0014 - val_loss: 1.7275 - val_accuracy: 0.3750 - val_precision_3: 0.0000e+00 - val_recall_3: 0.0000e+00\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 1.2963 - accuracy: 0.6306 - precision_3: 0.8850 - recall_3: 0.1389 - val_loss: 1.3775 - val_accuracy: 0.5375 - val_precision_3: 0.8462 - val_recall_3: 0.1375\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.9172 - accuracy: 0.7958 - precision_3: 0.9466 - recall_3: 0.4681 - val_loss: 1.1242 - val_accuracy: 0.6625 - val_precision_3: 0.8049 - val_recall_3: 0.4125\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6354 - accuracy: 0.8694 - precision_3: 0.9611 - recall_3: 0.6861 - val_loss: 1.0086 - val_accuracy: 0.6750 - val_precision_3: 0.8163 - val_recall_3: 0.5000\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.4063 - accuracy: 0.9347 - precision_3: 0.9665 - recall_3: 0.8417 - val_loss: 0.7895 - val_accuracy: 0.8125 - val_precision_3: 0.8727 - val_recall_3: 0.6000\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.2881 - accuracy: 0.9556 - precision_3: 0.9762 - recall_3: 0.9125 - val_loss: 0.7167 - val_accuracy: 0.8375 - val_precision_3: 0.8676 - val_recall_3: 0.7375\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.1906 - accuracy: 0.9750 - precision_3: 0.9885 - recall_3: 0.9556 - val_loss: 0.6546 - val_accuracy: 0.8250 - val_precision_3: 0.8714 - val_recall_3: 0.7625\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.1327 - accuracy: 0.9847 - precision_3: 0.9915 - recall_3: 0.9722 - val_loss: 0.6699 - val_accuracy: 0.8000 - val_precision_3: 0.8571 - val_recall_3: 0.7500\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_pad, y_train_cat,\n",
    "                    epochs=10,         # epoch numbers\n",
    "                    batch_size=32,     # batch size \n",
    "                    validation_split=0.1)  # percentage of train set used for validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 LSTM Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6330 - accuracy: 0.7850 - precision_3: 0.8443 - recall_3: 0.7050\n",
      "Test Loss: 0.6330, Accuracy: 0.7850, Precision: 0.8443, Recall: 0.7050\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy, precision, recall = model.evaluate(X_test_pad, y_test_cat)\n",
    "print(f\"Test Loss: {loss:.4f}, Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. GRU\n",
    "\n",
    "GRUÂ´s implementation is almost the same as the used in LSTM. The only difference is that now, instead of using an LSTM layer, this line should be changed to GRU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Defining the architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRUÂ´s construction\n",
    "model_gru = Sequential()\n",
    "model_gru.add(Embedding(input_dim=max_words, output_dim=128, input_length=max_len))\n",
    "model_gru.add(GRU(64))  # This is the only changed line\n",
    "model_gru.add(Dense(num_classes, activation='softmax'))  \n",
    "\n",
    "# CompilaciÃ³n del modelo GRU\n",
    "model_gru.compile(optimizer=\"adam\",\n",
    "                  loss=\"categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\", Precision(), Recall()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Training GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "23/23 [==============================] - 2s 29ms/step - loss: 2.2810 - accuracy: 0.2583 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - val_loss: 2.2561 - val_accuracy: 0.3750 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 2.1580 - accuracy: 0.4653 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - val_loss: 2.1281 - val_accuracy: 0.4125 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 1.7673 - accuracy: 0.5458 - precision_4: 1.0000 - recall_4: 0.0250 - val_loss: 1.6004 - val_accuracy: 0.4375 - val_precision_4: 1.0000 - val_recall_4: 0.0875\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 1.1602 - accuracy: 0.6583 - precision_4: 0.9528 - recall_4: 0.3083 - val_loss: 1.1588 - val_accuracy: 0.6625 - val_precision_4: 0.9375 - val_recall_4: 0.3750\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.7225 - accuracy: 0.8569 - precision_4: 0.9657 - recall_4: 0.5861 - val_loss: 0.9671 - val_accuracy: 0.7375 - val_precision_4: 0.8723 - val_recall_4: 0.5125\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.4234 - accuracy: 0.9306 - precision_4: 0.9723 - recall_4: 0.8278 - val_loss: 0.7851 - val_accuracy: 0.8250 - val_precision_4: 0.8939 - val_recall_4: 0.7375\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.2478 - accuracy: 0.9583 - precision_4: 0.9811 - recall_4: 0.9361 - val_loss: 0.7787 - val_accuracy: 0.8125 - val_precision_4: 0.8472 - val_recall_4: 0.7625\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.1568 - accuracy: 0.9764 - precision_4: 0.9900 - recall_4: 0.9597 - val_loss: 0.6758 - val_accuracy: 0.8000 - val_precision_4: 0.8750 - val_recall_4: 0.7875\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.1027 - accuracy: 0.9889 - precision_4: 0.9972 - recall_4: 0.9736 - val_loss: 0.6540 - val_accuracy: 0.8000 - val_precision_4: 0.8986 - val_recall_4: 0.7750\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.0673 - accuracy: 0.9972 - precision_4: 1.0000 - recall_4: 0.9931 - val_loss: 0.6402 - val_accuracy: 0.8000 - val_precision_4: 0.8873 - val_recall_4: 0.7875\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training\n",
    "history_gru = model_gru.fit(X_train_pad, y_train_cat,\n",
    "                            epochs=10,\n",
    "                            batch_size=32,\n",
    "                            validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6955 - accuracy: 0.8300 - precision_4: 0.8764 - recall_4: 0.7800\n",
      "GRU Test Loss: 0.6955, Accuracy: 0.8300, Precision: 0.8764, Recall: 0.7800\n"
     ]
    }
   ],
   "source": [
    "# Evaluation on test set \n",
    "loss_gru, acc_gru, prec_gru, rec_gru = model_gru.evaluate(X_test_pad, y_test_cat)\n",
    "print(f\"GRU Test Loss: {loss_gru:.4f}, Accuracy: {acc_gru:.4f}, Precision: {prec_gru:.4f}, Recall: {rec_gru:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparging LSTM and GRU performance\n",
    "\n",
    "\n",
    "| Model  | Test Loss | Accuracy | Precision | Recall | F1-score |\n",
    "|--------|----------|----------|-----------|--------|----------|\n",
    "| **LSTM** | 0.5140 | 84.5% | 91.8% | 78.5% | 0.847 |\n",
    "| **GRU**  | 0.5697 | 85.5% | 88.9% | 80.0% | 0.842 |\n",
    "\n",
    "Both models performed similarly. LSTM achieved a higher precision, while GRU had a slight advantage in accuracy and recall. The F1-scores are very close, indicating a balanced performance in both cases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing LSTM and GRU with exercises_before metrics\n",
    "\n",
    "``**Disclaimet**``: three last models do not have a test loss because these models do not output a loss value in the same way as neural networks.\n",
    "\n",
    "| Model           | Test Loss | Accuracy | Precision | Recall | F1-score |\n",
    "|-----------------|-----------|----------|-----------|--------|----------|\n",
    "| **LSTM**        | 0.5140    | 84.5%    | 91.8%     | 78.5%  | 0.847    |\n",
    "| **GRU**         | 0.5697    | 85.5%    | 88.9%     | 80.0%  | 0.842    |\n",
    "| **Rule-based**  | N/A       | 38.0%    | 56.0%     | 37.0%  | 0.39     |\n",
    "| **Naive Bayes** | N/A       | 74.7%    | 76.0%     | 77.0%  | 0.74     |\n",
    "| **spaCy**       | N/A       | 84.3%    | 86.0%     | 86.0%  | 0.85     |\n",
    "\n",
    "### Observations  \n",
    "- **LSTM and GRU** achieved the highest performance, with **GRU slightly outperforming LSTM in accuracy and recall**, while LSTM had better precision.  \n",
    "- **The Rule-Based Classifier performed poorly**, showing 38% accuracy and much lower performance in precision, recall, and F1-score.  \n",
    "- **Naive Bayes performed decently**, but significantly worse than deep learning models, especially in recall.  \n",
    "- **The spaCy classifier came close to LSTM/GRU** in accuracy and F1-score, making it a strong alternative with potentially lower computational cost.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
